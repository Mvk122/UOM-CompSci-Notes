# 2018-2019

## 21
* Tessellation would be applied to break the shape down into triangles.
* The lines EG, EG, EG would be extended until they reach the boundaries set by ABCD.
* The polygons encompassing these lines would then become new polygons.
* If these polygons are not triangles, the process continues until they are.

## 22
* The screens that view the images are 2D hence a projection needs to be done to represent the 3d model in 2d space.
* Real world lighting is too complicated with the tremendous amount of light bounces as well as the high precision that would be required to accurately model light hence rasterization models or low accuracy raytracing is used for illumination.
* There is a limited range of colours that hardware like monitors can represent hence the conceptual model needs to be represented using colours that can be reproduced by screens.

## 23
* First -E can be applied as a displacement  transformation on all the models in the scene.
* Then the camera's axes can be rotated such that F is coincident with -Z. The matrix for this operation can be applied to models in the scene.

## 24
* First the vector normals for A, B and C are calculated by taking the average of the normals of the polygons around them.
* Then we can interpolate between these 3 normals over the scan lines of the pixels to get a normal for the pixel.
* Then the local illumination model can be applied to each of the pixels in the scan line.

## 25
* N is the surface normal of the surface and is perpendicular to the surface.
* R is the reflected specular light from the light P and has the highest intensity of any of the light rays bouncing off the surface.
* Since reflections have a range of reflections, V is another bounce of light with an intensity that is proportional to R (with other aspects like the colour staying the same) and has its intensity take the equation of $I_pcos^n(x)$ where n is arbitrary and x is the angle between R and V.

## 26
* Noise can be caused by compression artefacts, randomness in the variance of photons etc.

## 27
* Box filter: sets the value of the pixel to the average of the pixels around it.
* Weighted Average filter: Sets the value of the pixel to the average of the pixels around it except the pixels are multiplied by their corresponding weights before averaging.
* Median filter: The pixel is set to the median value of the pixels surrounding it.
* All of these introduce smoothing into the image, the box filter is the simplest and removes noise at the cost of smoothing, weighted average filters allow for more control over the blurring process and median filters are the most computationally intensive but reduces noise while preserving image detail (Not as much blurring)

## 28 
* Template matching is correlation wherein we are trying to find a smaller image within an image by using the smaller image as the kernel.
* The correlation is done by iterating through the image and setting the value of the pixel in the centre of the template as the average of the values of the neighbouring pixels multiplied by the pixel in the template.
* Thus in the output image, the brightest areas are the areas that match the template the most.
* Care needs to be taken however at the edges of the image as it does not have neighbours on all sides hence it either needs to be cut off (reducing the resolution of the image) or assuming the values outside of the image are 0 (creates a line)
* The limitations:
	* This only matches an exact template hence if the object in the image is scaled/rotated, there will be no match.
	* This only matches a pixel perfect match hence it is no good if we are trying to find if a person is in a photo given another photo of them.