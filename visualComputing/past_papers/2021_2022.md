# 2021-2022

## 21
* In simple shading, humans can easily see the edges of the vertexes in a shaded image. 
* This is countered by the gouraud shading algorithm which gets the surface normals for a vertex by taking the average of the surface normals of the surfaces around the vertex.
* It then interpolates the values across each polygon by interpolating between the value of the surface normal and the value of the vertex.
* This smooths out the image and the edges can not be seen (At least for edges that are connected to other edges).

## 22
* Edges that are not connected in all sides to other surfaces are not smoothed out hence it can still look blocky.
* Furthermore it flattens out highlights.

## 24
* The matrices are transforming a mesh.
* The first matrix is a scaling matrix and scales the Y value by 2.
* The second matrix is a displacement matrix and it increments the x and y values by 1.
* The third matrix is a rotation matrix and it rotates the model by 30 degrees.

## 25
* the mesh is scaled 2x in the y axis, moved by 1 in both the x and y axis and then rotated around the origin by 30 degrees.

## 26
* $B_vN_v$ represents the magnitude of the gradient in the vertical direction.
* $B_uN_u$ represents the magnitude of the gradient in the horizontal direction.
* These 2 values can be used to change how diffuse lighting bounces off the object, thus making the surface look bumpy
* It is better to compute it in advance to save on processing power in the case that the bump map is constant as this would lead to better run-time performance at the cost of more storage.
* They can't be computed in advance if the texture is calculated in real time (eg to react to other elements during runtime).
* Precomputed bump maps would be better in the case of static textures eg a wall in a 3d rendering.
* Live bump maps would be better in a game using a water texture that is computed on the fly to interact with the game world.

## 28
* Connected component analysis is used to label the different blobs in an image.
* It is done in 2 passes:
1. In the first pass go through each pixel that is identified to be part of an object:
	* If none of the neighbours of it have a label, give it the next available pixel
	* If 1 or more neighbours have the same label, give it the same label
	* If 2 or more of the neighbours have different labels, give it any one but take a note of this ambiguity and the potential other labels it could have been given.
2. Run through the image again, relabelling pixels that are connected to other blocks of large labels. 

## 29
* An image histogram can be created by going through the pixels of the image and incrementing the corresponding intensity value in the histogram.
* The histogram can be displayed as a bar chart where each column represents a pixel intensity and the height of the bar represents the amount of pixels that have that pixel intensity.
* The histogram can be used to change the brightness, contrast or thresholding the image by scaling or displacing the values in the histogram or by cutting off the histogram at a certain threshold.

## 30
* Clipping in pixel manipulation is used to restrict the values that pixels in an image can take,
* This is used to prevent either overflow or underflow in a pixel while calculating values for the pixel.
* This can prevent overflows where the pixel value is set too high and rolls over, becoming small again, creating an inaccurate representation of the image.

## 31
* Convolutions are done by iterating the kernel through each pixel of the image.
* The manipulation occurs on pixel in the centre of the kernel wherein it takes the value of multiplying the values in the kernel to the corresponding pixel value and summing them up. (This is the generally incorrect usage of the word `convolution`, more accurately, the top left of the kernel corresponds to the bottom left pixel and so on and so forth hence the kernel is flipped both horizontally and vertically).
* Example kernels:
```
Blurring kernel

1 2 1 
2 4 1 
1 2 1

Edge detection kernel
-1 0
0 1
```


## 32
* This demonstration will be done using cartesian coordinates.
* The equation `y = mx + c` is rearranged to `c = -xm + y`.
* Then for a given pixel eg (10, -10) we can create the equation `c = -10m - 10`
* We can then set c = 0 and m = 0 in turn to get the values of c and m when the line intersects either of the axes.
* We can use a table where the rows are m values and the columns are c values.
* We can increment the corresponding value in the table for each pixel with the same c and m value.
* A line exists for any value in the table that has a value of 3 or more (other higher thresholding values can also be used)

