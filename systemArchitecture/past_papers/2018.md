## 1a
* Compulsory misses: the data is not in the cache as the cache is cold.
* Capacity misses: The cache is full and more space had to be made
* Conflict misses: Due to the associativity of the cache, a specific data entry had to be removed.

## 1b
1. Spatial locality: If a memory location was accessed, memory locations around it are likely to be accessed too. Can be done by using a heap.
2. Temporal locality: If a memory location was accessed, it is likely to be accessed again in the near future. Can be done by doing all necessary computations on a data item and its neighbours at once before moving on (blocking).

## 1c1
(4 * 0.9) + (0.1 * 0.9 * 16) + (0.01 * 216) = 7.2

## 1c2
(4 * 0.95) + (0.05 * 0.9 * 16) + (0.005 * 216) = 5.6

## 1c3
(4 * 0.9) + (16 * 0.1) = 5.2 yes it is an improvement as it takes 5.2 cycles on average instead of 5.6.

## 1c4
Yes it is now better to use the c2 as this only takes 4.82 cycles on average.

## 2a
* It is better to choose the first option as there will be more flexibility in choosing the RAID setup for either better performance with RAID0 or redundancy with RAID1

## 2b
I don't think this is part of the course anymore

## 3a
* Dependencies:
	* RAW:
		* (2,1)
		* (4,3)
		* (5,6)
		* (7,8)
		* (2,7)
		* (4,7)
		* (6,8)
	* WAW:
		* (2,1)
		* (4,3)
		* (5,6)
		* (7,8)
		* (2,7)
	* WAR:
		* (7,8)
		* (2,7)
* The RAW dependencies can be solved through forwarding in all cases except for those where the arithmetic instructions are 1 instruction behind their corresponding Load operations. Thus there are 3 1 cycle gaps hence the total cycles is: 
	* 8 + 3 + 4 = 15
	* CPI = 15 /8 = 1.875

## 3b
* Execution time can be minimised by leaving a gap between arithmetic and load instructions hence the new order is:
LDR R1, X  
LDR R2, Y  
LDR R3, Z
MUL R1, R1, R1  
MUL R2, R2, R2  
MUL R3, R3, R3  
ADD R1, R1, R2  
ADD R1, R1, R3
Now it takes 8 + 4 cycles = 12 thus CPI of 1.5


## 3c
* Tomasulo uses a distributed approach with reservation stations and a common data bus whereas scoreboarding uses a centralized approach hence tomasulo scales better.
* Scoreboarding writes to registers directly, allowing it to write to multiple registers in 1 cycle whereas tomasulo needs to write to the CDB hence only one write can be done at a time.
* Tomasulo uses register renaming to avoid WAR and WAW whereas scoreboarding stalls upon WAW and WAR.
* Tomasulo writes to the CDB forwards the data seamlessly whereas scoreboarding needs a cycle to write and then read from the register bank. 

## 4a
* Cache coherence is a problem in multicore systems wherein each core has its own distinct L1 cache. 
* Since multiple copies of the same data item can be used by multiple cores, cache coherence refers to ensuring that changes in the data are seen at once in all caches to ensure that separate cores are not using out of date values.

## 4b
* Similarities: 
	* Both use the MESI protocol to communicate the state and change in state that the cache data is in in multiple cores. 
	* Both can use either `invalidate` or `update` protocols whereas invalidate is preferred.
	* They both also support the MOESI protocol.
* Differences: 
	* In snoopy, there is a bus that connects all the caches for status updates whereas in directory, caches only communicate with the directory through a network on chip (or the distributed directory).
	* In directory, the directory stores the state of each cache item as well as which cache it is in. In snoopy, the caches themselves do this job.
	* In snoopy they only store the cache state, directories need to store the cache state, sharing vector and directory state.
	* Snoopy minimises the number of messages sent whereas directory can use multiple.
	* Directory scales better 
	* Snoopy can be scaled better using a hierarchy of busses, directory scales by having more directories.
	* The bus can only send 1 message at once whereas the NOC of the directory can send multiple.

## 4c
* Provider 1:
	* Single threaded IPS: `4* 2GHz` = 8*(10^9)
	* Peak IPC: `8 cores * 4 way superscalar` = 32
	* Peak IPS: `8 cores * 4 way superscalar * 2Ghz` = 64 * (10^9)
	* Threads: `2 threads *  8 cores` = 16
* Provider 2:
	* Single threaded IPS: `3 * 1GHz` = 3 * (10^9)
	* Peak IPC: `3 * 36 cores` = 108
	* Peak IPS: `3 * 36 cores * 1GHz` = 108 * (10^9)
	* Threads: 36
* Provider 1:
	* Single threaded IPS: 2.7 * 2Ghz = 5.4 * (10^9)
	* Multithreaded IPS: 1.5 * 2GHz * 8 * 2 threads = 48 * (19^9)
* Provider 2: 
	* Single threaded IPS: 1.4 * 1GHz = 1.4 * (10^9)
	* Multithreaded IPS: 1.4 * 1GHz * 36 = 50.4 * (10^9)
* Thus provider 1 is better with a total score of 53.4 vs 51.8.